{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /Users/Laura/anaconda3/envs/cogs118b/lib/python3.10/site-packages (2.2.2)\n",
      "Requirement already satisfied: torchvision in /Users/Laura/anaconda3/envs/cogs118b/lib/python3.10/site-packages (0.17.2)\n",
      "Requirement already satisfied: torchaudio in /Users/Laura/anaconda3/envs/cogs118b/lib/python3.10/site-packages (2.2.2)\n",
      "Requirement already satisfied: filelock in /Users/Laura/anaconda3/envs/cogs118b/lib/python3.10/site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /Users/Laura/anaconda3/envs/cogs118b/lib/python3.10/site-packages (from torch) (4.11.0)\n",
      "Requirement already satisfied: sympy in /Users/Laura/anaconda3/envs/cogs118b/lib/python3.10/site-packages (from torch) (1.13.2)\n",
      "Requirement already satisfied: networkx in /Users/Laura/anaconda3/envs/cogs118b/lib/python3.10/site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in /Users/Laura/anaconda3/envs/cogs118b/lib/python3.10/site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /Users/Laura/anaconda3/envs/cogs118b/lib/python3.10/site-packages (from torch) (2024.10.0)\n",
      "Requirement already satisfied: numpy in /Users/Laura/anaconda3/envs/cogs118b/lib/python3.10/site-packages (from torchvision) (1.24.3)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /Users/Laura/anaconda3/envs/cogs118b/lib/python3.10/site-packages (from torchvision) (11.0.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/Laura/anaconda3/envs/cogs118b/lib/python3.10/site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/Laura/anaconda3/envs/cogs118b/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: ftfy in /Users/Laura/anaconda3/envs/cogs118b/lib/python3.10/site-packages (6.3.1)\n",
      "Requirement already satisfied: regex in /Users/Laura/anaconda3/envs/cogs118b/lib/python3.10/site-packages (2024.11.6)\n",
      "Requirement already satisfied: tqdm in /Users/Laura/anaconda3/envs/cogs118b/lib/python3.10/site-packages (4.67.1)\n",
      "Requirement already satisfied: wcwidth in /Users/Laura/anaconda3/envs/cogs118b/lib/python3.10/site-packages (from ftfy) (0.2.13)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting git+https://github.com/openai/CLIP.git\n",
      "  Cloning https://github.com/openai/CLIP.git to /private/var/folders/vf/zqlzjbwd7m78dmhj80bm10280000gn/T/pip-req-build-oid_v44r\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/openai/CLIP.git /private/var/folders/vf/zqlzjbwd7m78dmhj80bm10280000gn/T/pip-req-build-oid_v44r\n",
      "  Resolved https://github.com/openai/CLIP.git to commit dcba3cb2e2827b402d2701e7e1c7d9fed8a20ef1\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: ftfy in /Users/Laura/anaconda3/envs/cogs118b/lib/python3.10/site-packages (from clip==1.0) (6.3.1)\n",
      "Requirement already satisfied: packaging in /Users/Laura/anaconda3/envs/cogs118b/lib/python3.10/site-packages (from clip==1.0) (24.2)\n",
      "Requirement already satisfied: regex in /Users/Laura/anaconda3/envs/cogs118b/lib/python3.10/site-packages (from clip==1.0) (2024.11.6)\n",
      "Requirement already satisfied: tqdm in /Users/Laura/anaconda3/envs/cogs118b/lib/python3.10/site-packages (from clip==1.0) (4.67.1)\n",
      "Requirement already satisfied: torch in /Users/Laura/anaconda3/envs/cogs118b/lib/python3.10/site-packages (from clip==1.0) (2.2.2)\n",
      "Requirement already satisfied: torchvision in /Users/Laura/anaconda3/envs/cogs118b/lib/python3.10/site-packages (from clip==1.0) (0.17.2)\n",
      "Requirement already satisfied: wcwidth in /Users/Laura/anaconda3/envs/cogs118b/lib/python3.10/site-packages (from ftfy->clip==1.0) (0.2.13)\n",
      "Requirement already satisfied: filelock in /Users/Laura/anaconda3/envs/cogs118b/lib/python3.10/site-packages (from torch->clip==1.0) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /Users/Laura/anaconda3/envs/cogs118b/lib/python3.10/site-packages (from torch->clip==1.0) (4.11.0)\n",
      "Requirement already satisfied: sympy in /Users/Laura/anaconda3/envs/cogs118b/lib/python3.10/site-packages (from torch->clip==1.0) (1.13.2)\n",
      "Requirement already satisfied: networkx in /Users/Laura/anaconda3/envs/cogs118b/lib/python3.10/site-packages (from torch->clip==1.0) (3.3)\n",
      "Requirement already satisfied: jinja2 in /Users/Laura/anaconda3/envs/cogs118b/lib/python3.10/site-packages (from torch->clip==1.0) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /Users/Laura/anaconda3/envs/cogs118b/lib/python3.10/site-packages (from torch->clip==1.0) (2024.10.0)\n",
      "Requirement already satisfied: numpy in /Users/Laura/anaconda3/envs/cogs118b/lib/python3.10/site-packages (from torchvision->clip==1.0) (1.24.3)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /Users/Laura/anaconda3/envs/cogs118b/lib/python3.10/site-packages (from torchvision->clip==1.0) (11.0.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/Laura/anaconda3/envs/cogs118b/lib/python3.10/site-packages (from jinja2->torch->clip==1.0) (2.1.3)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/Laura/anaconda3/envs/cogs118b/lib/python3.10/site-packages (from sympy->torch->clip==1.0) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# %conda install --yes -c pytorch pytorch=1.7.1 torchvision cudatoolkit=11.0\n",
    "%pip install torch torchvision torchaudio\n",
    "%pip install ftfy regex tqdm\n",
    "%pip install git+https://github.com/openai/CLIP.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version: 3.10.15 (main, Oct  3 2024, 02:33:33) [Clang 14.0.6 ]\n",
      "\n",
      "Python path:\n",
      "/Users/Laura/anaconda3/envs/cogs118b/lib/python310.zip\n",
      "/Users/Laura/anaconda3/envs/cogs118b/lib/python3.10\n",
      "/Users/Laura/anaconda3/envs/cogs118b/lib/python3.10/lib-dynload\n",
      "\n",
      "/Users/Laura/anaconda3/envs/cogs118b/lib/python3.10/site-packages\n",
      "/Users/Laura/anaconda3/envs/cogs118b/lib/python3.10/site-packages/setuptools/_vendor\n",
      "\n",
      "Installed packages:\n",
      "clip - Version: 1.0\n",
      "\n",
      "CLIP import successful!\n",
      "Available models: ['RN50', 'RN101', 'RN50x4', 'RN50x16', 'RN50x64', 'ViT-B/32', 'ViT-B/16', 'ViT-L/14', 'ViT-L/14@336px']\n"
     ]
    }
   ],
   "source": [
    "#to check if CLIP is successfully installed\n",
    "import sys\n",
    "import site\n",
    "print(\"Python version:\", sys.version)\n",
    "print(\"\\nPython path:\")\n",
    "for path in sys.path:\n",
    "    print(path)\n",
    "\n",
    "print(\"\\nInstalled packages:\")\n",
    "import pkg_resources\n",
    "for package in pkg_resources.working_set:\n",
    "    if \"clip\" in package.key.lower():\n",
    "        print(f\"{package.key} - Version: {package.version}\")\n",
    "\n",
    "try:\n",
    "    import clip\n",
    "    print(\"\\nCLIP import successful!\")\n",
    "    print(\"Available models:\", clip.available_models())\n",
    "except ImportError as e:\n",
    "    print(\"\\nFailed to import CLIP:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully on cpu\n",
      "\n",
      "Embedding shape: (1, 512)\n",
      "First few values: [-0.00865016 -0.00933015  0.01677416 -0.02888286  0.03435755]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import clip\n",
    "from PIL import Image\n",
    "\n",
    "def get_clip_embedding(image_path):\n",
    "    # Load the model\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    model, preprocess = clip.load(\"ViT-B/32\", device=device)\n",
    "    print(f\"Model loaded successfully on {device}\")\n",
    "    \n",
    "    # Load and preprocess the image\n",
    "    image = Image.open(image_path)\n",
    "    if image.mode != 'RGB':\n",
    "        image = image.convert('RGB')\n",
    "    image_input = preprocess(image).unsqueeze(0).to(device)\n",
    "    \n",
    "    # Get image features\n",
    "    with torch.no_grad():\n",
    "        image_features = model.encode_image(image_input)\n",
    "        # Normalize the features\n",
    "        image_features = image_features / image_features.norm(dim=-1, keepdim=True)\n",
    "    \n",
    "    return image_features.cpu().numpy()\n",
    "\n",
    "# How to use on one image\n",
    "if __name__ == \"__main__\":\n",
    "    image_path = \"/Users/Laura/Documents/cogs118b-final-project/dog.jpg\"\n",
    "    \n",
    "    embedding = get_clip_embedding(image_path)\n",
    "    print(f\"\\nEmbedding shape: {embedding.shape}\")\n",
    "    print(f\"First few values: {embedding[0, :5]}\")  # Show first 5 values"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cogs118b",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
